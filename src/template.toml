# mbf-fastq-processor Configuration Template
# This template includes all available transformation steps with explanations

# == input ==
# From input section documentation:
[input]
     read1 = ['fileA_1.fastq', 'fileB_1.fastq.gz', 'fileC_1.fastq.zstd']
#     read2 = ['fileA_1.fastq', 'fileB_1.fastq.gz', 'fileC_1.fastq.zstd'] # (optional)
#     index1 = ['index1_A.fastq', 'index1_B.fastq.gz', 'index1_C.fastq.zstd'] # (optional)
#     index2 = ['index2_A.fastq', 'index2_B.fastq.gz', 'index2_C.fastq.zstd'] # (optional)
#     # but if index1 is set, index2 must be present as well
#     interleaved = false # (optional) read1 is actually read1/2 interleaved.
#                   Read2 must not be set.


# == Output ==

[output]
     prefix = "output" # files get named {prefix}_1{suffix}, _2, _i1, _i2. Default is 'output'
     format = "Gzip" # (optional), defaults to 'Raw'
                     # Valid values are Raw, Gzip, Zstd and None
                     # None means no fastq output (but we need the prefix for Reports etc.)
#     suffix = ".fq.gz" # optional, determined by the format if left off.

     report_json = true # (optional) write a json report file ($prefix.json)?
     report_html = true # (optional) write an interactive html report report file ($prefix.html)?

#     stdout = false # write Read1 to stdout, do not produce other fastq files.
#                    # set's interleave to true (if Read2 is in input),
#                    # format to Raw
#                    # You still need to set a prefix for
#                    # Reports/keep_index/Inspect/QuantifyRegion(s)
#                    # Incompatible with a Progress Transform that's logging to stdout
#
#     interleave = false # (optional) interleave fastq output, producing
#                        # only a single output file for read1/read2
#                        # (with infix _interleaved instead of '_1', e.g. 'output_interleaved.fq.gz')
#     keep_index = false # (optional) write index to files as well? (optional)
#                        # (independent the interleave setting. )
#     output_hash = false # (optional) write a {prefix}_{1|2|i1|i2}.sha256
#                         # with a hexdigest of the (uncompressed) data's sha256,
#                         # just like sha256sum would do.
#

# ==== Demultiplex ====
# Uncomment to demultiplex samples based on barcodes
# [[step]]]
#     action = "Demultiplex"
#     regions = [ # Where are the barcodes located?
#         {source = "read1", start=0, length=6},
#         {source = "read1", start=10, length=6},
#     ]
#     max_hamming_distance = 0 # if a barcode doesn't match, how many mismatches are allowed?
#     output_unmatched  = true # if set, write reads not matching any barcode
#                              #  to a file like ouput_prefix_no-barcode_1.fq
#
# [step.barcodes] # with single square brackets!
# # separate multiple regions with a _
# # a Mapping of barcode -> output name.
# AAAAAA_CCCCCC = "sample-1" # output files will be named prefix.barcode_prefix.infix.suffix
#                            # e.g. output_sample-1_1.fq.gz
#                            # e.g. output_sample-1_report.fq.gz


# == Tagging ==
# Extract data from sequences, and reapply it.
# tags get temporarily stored in memory under a 'label'
# and can then be used in other steps.

# ==== ExtractIUPAC ====
# # Extract a IUPAC string.
# [[steps]]
#    action = "ExtractIUPAC"
#    label = "mytag"
#    anchor = 'Anywhere' # Left | Right | Anywhere - Where to search.
						 # Left only matches at the start of the read, etc.
#    query = 'CTN' # what we are searching
#    target = 'Read1' # where we are searching it.

# ==== ExtractRegex ====
## Extract a regexp result. Stores an empty string if not found.
# [[steps]]
#    action = "ExtractRegex"
#    label = "mytag"
#    search = '^CT(..)CT'
#    replace = "$1"  # standard regex replacement syntax
#    target = 'Read1' # where we are searching it.


# ==== ExtractRegion ====
## Extract a fixed position region
# [[step]]
#    action = "ExtractRegion"
#    start = 5
#    len = 8
#    source = "Read1" #|"Read2"|"Index1"|"Index2"
#    label = "umi"

# ==== ExtractRegions ====
## Extract from fixed position regions
# [[step]]
#    action = "ExtractRegions"
#    regions = [
#		{source= "Read1", start = 0, length = 8},
#		{source= "Read1", start = 12, length = 4},
#    ]
#    label = "barcode"
#    separator: "_" #(optional) str, what to put between the regions, defaults to '_', may be empty

# ==== ExtractLength ====
## Extract the length of a read as a tag
# [[steps]]
#    action = "ExtractLength"
#    label = "mytag"


# ==== RemoveTag ====
## forget about a tag
## usefull if you want to store tags in a table,
## but not this one
# [[steps]]
#    action = "RemoveTag"
#    label = "mytag"



# == Filters ==

# ==== FilterByTag ====
## Remove sequences that have (or don't have) a tag
# [[steps]]
#    action = "FilterByTag"
#    label = "mytag"
#    keep_or_remove = "Keep" # or "Remove"


# == Edits ==

# ==== StoreTagInSequence ====
## Store the tag's replacement in the sequence,
## replacing the original sequence at that location.
# [[steps]]
#    action = "StoreTagInSequence"
#    label = "mytag"
#    ignore_missing = true # if false, an error is raised if the tag is missing


# ==== StoreTagInComment ====

## Store currently present tags as comments on read names.
## Comments are key=value pairs, separated by `comment_separator`
## which defaults to '|'.
## They get inserted at the first `comment_insert_char`,
## which defaults to space. The comment_insert_char basically moves
## to the right.
##
## That means a read name like
## @ERR12828869.501 A00627:18:HGV7TDSXX:3:1101:10502:5274/1
## becomes
## @ERR12828869.501|key=value|key2=value2 A00627:18:HGV7TDSXX:3:1101:10502:5274/1
##
## This way, your added tags will survive STAR alignment.
## (STAR always cuts at the first space, and by default also on /)
##
## (If the comment_insert_char is not present, we simply add at the right)
##
##
## Be default, comments are only placed on Read1.
## If you need them somewhere else, or an all reads, change the target (to "All")
# [[steps]]
#    action = "StoreTagInComment"
#    label = "mytag" # if set, only store this tag
#    target = "Read1" # |"Read2"|"Index1"|"Index2"|"All"
#    comment_insert_char = ' ' # (optional) char at which to insert comments
#    comment_separator = '|' # (optional) char to separate comments
#    region_separator = '_' # (optional) char to separate regions in a tag, if it has multiple

# ==== StoreTaglocationInComment ====
## store the coordinates of a tag in the comment
## start-end, 0-based, half-open
# [[steps]]
#    action = "StoreTaglocationInComment"
#    label = "mytag"
#    target = "Read1" # |"Read2"|"Index1"|"Index2"|"All"
#    comment_insert_char = ' ' # (optional) char at which to insert comments
#    comment_separator = '|' # (optional) char to separate comments


# ==== LowercaseTag ====
## turns a tag into lowercase
# [[steps]]
#    action = "LowercaseTag"
#    label = "mytag"

# === TrimAtTag ===
## Trim the read at the position of a tag
# [[steps]]
#    action = "TrimAtTag"
#    label = "mytag"
#    direction = "Start" # or "End"
#    keep_tag = false # if true, the tag sequence is kept in the read,
#                     # swappes wether we trim at the start/end of the tag.

# == Others ==

# ==== StoreTagsInTable ====
## store the tags in a tsv table
# [[steps]]
#    action = "StoreTagsInTable"
#    table_file = "tags.tsv"
#    compression = "Raw" # Raw, Gzip, Zstd
#    region_separator = "_" # (optional) char to separate regions in a tag, if it has multiple

# ==== QuantifyTag ===
## Count the occurances of each tag-sequence
# [[steps]]
#    action = "QuantifyTag"
#    label = "mytag"
#    infix = "tagcount" # output file is output_prefix_infix.tag.qr.json


